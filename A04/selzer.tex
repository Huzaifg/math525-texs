\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\pagestyle{empty}
\usepackage{graphicx} % For including images
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\begin{document}
\section{Problem 1}
\subsection{a}
We know that, for a basic feasible solution $x$ associated with basis matrix $B$, that $\bar{c}_i>0$, for all indices $i$ within the set of nonbasic indices $N$. We must show that $x$ is a unique optimal solution.

Consider any arbitrary feasible solution $y$, and the vector $y-x$. Since both $x$ and $y$ are feasible, we have $Ax=Ay=b$, meaning that $Ad=Ax-Ay=b-b=0$.

$Ad$ is equivalent to the form

$$
Bd_B + \sum_{i\in N} A_id_i=0
$$

Since $B$ is invertible, we have 

$$
d_B = -\sum_{i\in N}B^{-1}A_id_i
$$

and

$$
c'd=c'_Bd_B + \sum_{i\in N}c_id_i=\sum_{i\in N}(c_i-c'_BB^{-1}A_i)d_i=\sum_{i\in N}\bar{c_i}d_i
$$

For all nonbasic indices $i\in N$, we have $x_i=0$, and since $y$ is a feasible solution, we have $y_i\geq 0$. Therefore $d_i\geq 0$. We also know that $c_i>0$ for all $i\in N$. Therefore $c'd\geq 0$. 

Furthermore, since all $c_i>0$, we know that $c'd=0$ only if $d_i=0$ for all $i\in N$. If this is the case, then we have 

\begin{equation}
\begin{split}
d_B=-\sum_{i\in N} B^{-1}A_id_i \\
d_B=-\sum_{i\in N} B^{-1}A_i(0) \\
d_B=0
\end{split}
\end{equation}

Thus $d=0$, and $y=x$. This means that for any $y\neq x$, $c'd>0$, meaning $c'y>c'x$ for any feasible $y$. Thus, by definition, $x$ is a unique optimal solution.

\subsection{b}

We know that $x$ is a unique optimal nondegenerate solution, and we must show that the reduced cost of every nonbasic variable is positive. We provide a proof by contradiction.

Suppose that $x$ is a uniquely optimal, nondegenerate basic feasible solution, and that $\bar{c}_j\leq 0$ for some nonbasic variable $x_j$. Since $x$ is a nondegenerate basic feasible solution, the $j^{th}$ basic direction $d_j$ is a feasible direction and by definition there exists some feasible $y=x+\theta d_j$. Since the reduced cost $\bar{c}_j$ is non-positive, $c'y\leq c'x$.

If $c'y<c'x$, then $x$ is not optimal, and if $c'y=c'x$, then $x$ is optimal, but not uniquely so. Either way, we have reached a contradiction, and the reduced cost of \textbf{all} nonbasic variables are positive. 

Q.E.D.

\section{Problem 3}

We know that $x^*$ is an optimal basic feasible solution with a corresponding optimal basis $B^*$. 

\subsection{a}
We also know that $I$ is empty, meaning \textbf{all nonbasic indices} have corresponding reduced costs that are nonzero. 

We must show that $x^*$ is the only optimal solution. We provide a proof by contradiction, showing that the existence of another distinct optimal solution $y^*$ violates the optimality of the basis $B^*$.

Suppose that, there is another optimal solution $y^*\neq x^*$. Consider the feasible direction $d=y-x\neq0$. It follows that

$$
c'd=c'y-c'x=0
$$

Since $y^*$ is feasible, we know that

$$
y^*_N = x^*_N+d_N\geq 0
$$

But since x is a basic feasible solution $x_N^*=0$ and

$$
d_i\geq 0
$$

Furthermore, since $y^*$ and $x^*$ are both feasible, the equality conditions require $Ad=0$. Since $Ad=Bd_B+\sum_{i\in N}A_id_i$=0, we can see that if $d_i=0$ for all $i$, then $d=0$. This would be a contradiction, so there must exist some $j\in N$ such that $d_j>0$. 

We then rewrite $c'd$:

\begin{equation}
\begin{split}
c'd=c'_Bd_B + \sum_{i\in N}c_id_i\\
c'd=\sum_{i\in N}(c_i-c'_BB^{-1}A_i)d_i\\
c'd=\sum_{i\in N}\bar{c_i}d_i=0
\end{split}
\end{equation}

Thus we have $c'd=0=\sum_{i\in N}\bar{c}_id_i$. Since $B^*$ is an optimal basis, Definition 3.3 tells us that $\bar{c}\geq 0$. Since $I$ is empty, $\bar{c}_i\neq 0$ for all $i\in N$. Therefore, for all $i\in N$, $\bar{c}_i>0$. 

However, we know that $d_j>0$. Thus, $\bar{c}_jd_j>0$, and we have

\begin{equation}
\begin{split}
-\bar{c}_jd_j=\sum_{i\in N|i\neq j}\bar{c}_id_i\\
0>\sum_{i\in N|i\neq j}\bar{c}_id_i
\end{split}
\end{equation}

Since all $\bar{c}_i, d_i\geq0$, this summation cannot be negative, and we have reached our contradiction. Thus, if all of the problem constraints hold, $x^*$ must be the only optimal solution.

Q.E.D.

\subsection{b}

We prove both directions, referring to the "following linear programming problem" as $q$:

\underline{$x^*$ is the unique optimal solution $\Rightarrow$ $q$ has an optimal value of zero}

We first show that $x^*$ is a feasible solution to $q$ with cost $0$. Since $x^*$ is feasible, we satisfy $Ax=b$. By definition, $x^*_i=0$ for all $i\in N$, meaning we satisfy $x^*_i=0, i\in N\texttt{\textbackslash} I$. Since $x^*$ is feasible, we know that $x^*\geq 0$, meaning that we satisfy $x^*_i\geq 0$ for all $i\in B\cup I$. Finally, we note that since $I\subseteq N$, $x^*_i=0$ for all $i\in I$ and thus the cost of $x^*$ is 0. 

We now show that $x^*$ is the only solution to $q$, as the existence of any other solution would violate the unique optimality of $x^*$.

Consider any other solution $y$ to $q$. We know that $Ay=b$, and we also can combine the second and third constraints to show that $y\geq 0$; this means that $y$ is a feasible solution in our polyhedron.

Consider $d=y-x^*$. We note that 

$$
c'd=\sum_{i\in N}\bar{c}_id_i=\sum_{i\in N\texttt{\textbackslash}I}\bar{c}_id_i+\sum_{i\in I}\bar{c}_id_i
$$

Since both $x^*$ and $y$ are feasible solutions to $q$, we know that $x^*_i=y_i=0$, meaning $d_i=0$ for all $i\in N\texttt{\textbackslash}I$. Thus we have 

$$
c'd=\sum_{i\in I}\bar{c}_id_i
$$

But, by the definition of $I$, $\bar{c}_i=0$ for all $i\in I$, leading to

$$
c'd = 0
$$

Therefore $c'y=c'(x^*+d)=c'x^*+0=c'x^*$, and $y$ is also an optimal solution in our minimization problem. Thus, we have reached a contradiction, and for $x^*$ to be uniquely optimal there can be no other solutions to $q$.

Since $x^*$ is the only solution to $q$, the optimal cost of $q$ is its' optimal cost, i.e. 0.

Q.E.D.

\underline{$q$ has an optimal value of zero $\Rightarrow$ $x^*$ is the unique optimal solution }

We provide a proof by contrapositive. Suppose that $x^*$ is optimal, but not uniquely so, and that there exists some distinct optimal solution $y$.

Consider $d=y-x\neq 0$. Since $y$ and $x^*$ are feasible, 

$$
Ad=Ay-Ax=b-b=0
$$

We can rewrite this to yield the equation

$$
B^{*-1}d_B+\sum_{i\in N}A_id_i=0
$$

Which, rearranging to solve for $d_B$ yields

$$
d_B=-\sum_{i\in N}B^{*-1}A_id_i
$$

Considering this equation, it is clear that for $d\neq 0$ there must be some $j\in N$ such that $d_j\neq0$. Furthermore, $y$'s feasibility requires $y_j\geq 0$, and $x_j=0$, meaning $d_j>0$.

Since $x^*$ and $y$ are both optimal, they share the same optimal cost, and $c'd=0$. We can rewrite this as

$$
0=\sum_{i\in N}\bar{c}_id_i
$$

Since $B^*$ is an optimal basis, by definition we have $\bar{c}_i\geq 0$ . Since $y$ is feasible and $x_i=0$ for all $i\in N$, $d_i\geq 0$ for all $i\in N$. Since all terms are non-negative, the above equality only holds if all terms $\bar{c}_id_i=0$ for all $i\in N$. If $d_j>0$, then $\bar{c}_j=0$, which means $j\in I$.

We now consider $y$ in terms of the maximization problem $q$. Since $y$ is feasible in our minimization problem, we know that $Ay=b$ and $y_i\geq 0, i\in B\cup I$. Furthermore, since we know that $\bar{c}_id_i=0$ for all $i\in N$ and that $\bar{c}_i\neq 0$ for all $i\in N\texttt{\textbackslash}I$, $d_i=0$ for all $i\in N\texttt{\textbackslash}I$ and thus $y_i=d_i+x_i=0$ for all $i\in N\texttt{\textbackslash}I$. Thus $y$ is also a feasible solution to our maximization problem.

We finally consider the cost of $y$, which is

\begin{equation}
\begin{split}
\sum_{i\in I} y_i =\sum_{i\in I} x_i+d_i=\sum_{i\in I}d_i\\
\sum_{i\in I} y_i = d_j +\sum_{i\in I|i\neq j}d_i\\
\sum_{i\in I} y_i > 0
\end{split}
\end{equation}

Thus, $y$ has positive cost, and the optimal cost for $q$ must also be positive.

We have proven the contrapositive, and thus the original claim holds.

Q.E.D.

\section{Problem 4}
\subsection{a}

We can easily convert this problem into standard form by adding slack variables to the two non-negativity constraints of the problem:

$$
\begin{array}{ll}
\text{minimize}  & -2x_1-x_2\\
\text{subject to}& x_1-x_2+x_3=2\\
                 & x_1+x_2+x_4=6\\
                 & x_1, x_2, x_3, x_4\geq 0\\
\end{array}
$$

To construct a basic feasible solution $x$, we choose the linearly independent columns $A_3=\begin{bmatrix}1\\0\end{bmatrix}$ and $A_4=\begin{bmatrix}0\\1\end{bmatrix}$, with $B=\begin{bmatrix}A_3 & A_4\end{bmatrix}$. Thus we have $x_1=x_2=0$, and solve the remaining system of equations

$$
\begin{array}{c}
x_3=2\\
x_4=6\\
\end{array}
$$

to determine that $x_3=2, x_4=6$. Thus we have the initial basic feasible solution

$$
x=(0,0,2,6)
$$

\subsection{b}

We start by constructing the initial tableau:

$$
\begin{array}{c}
\\
 \\
x_3 \\
x_4 \\ 
\end{array}
\begin{array}{|c|cccc|c}
    & x_1 & x_2 & x_3 & x_4 &  \\ \hline
  0 & -2 & -1 & 0 & 0 & \\ \hline
  2 & 1 & -1 & 1 & 0 & \\
  6 & 1 & 1 & 0 & 1 & \\\hline
\end{array}
$$

Since $\bar{c}_1\leq 0$, we let $x_1$ enter the basis. The pivot column is $u=\begin{pmatrix}1 & 1\end{pmatrix}$, and we compute $\theta_i$, for $i=3,4$:

\begin{itemize}
\item $\theta_3=\frac{2}{1}=2$
\item $\theta_4=\frac{6}{1}=6$
\end{itemize}

We have $\theta^*=\text{min }\{\theta_3, \theta_4\}=2$, and we have $i=3, l=1$, and the first basic variable $x_3$ exits the basis. The new basis will be $\bar{B}(1)=1, \bar{B}(2)=4$.

After performing the row operations (described to the right), we obtain the following new tableau

$$
\begin{array}{c}
\\
 \\
x_1 \\
x_4 \\ 
\end{array}
\begin{array}{|c|cccc|l}
    & x_1 & x_2 & x_3 & x_4 & \\ \hline
  4 & 0 & -3 & 2 & 0 & R_0=R_0+2R_1 \\  \hline
  2 & 1 & -1 & 1 & 0 & R1=R1\\
  4 & 0 & 2 & -1 & 1 & R2 = R2 - R1\\\hline
\end{array}
$$

The corresponding basic feasible solution is $x=\begin{pmatrix}2 & 0 & 0 & 4\end{pmatrix}$

Now, we have $\bar{c}_2=-3$, so we let $x_2$ enter the basis. The pivot column is $u=\begin{pmatrix}-1 & 2\end{pmatrix}$, and we select $i=4,l=2$ since it is the only component of $u$ that is positive. $x_4$ exits the basis, and the new basis will be $\bar{B}(1)=1, \bar{B}(2)=2$.

After performing the row operations (described to the right), we obtain the following new tableau

$$
\begin{array}{c}
\\
 \\
x_1 \\
x_4 \\ 
\end{array}
\begin{array}{|c|cccc|l}
    & x_1 & x_2 & x_3 & x_4 & \\ \hline
  10& 0 & 0 & 0.5 & 0.75 & R_0=R_0+\frac{3R_2}{2} \\  \hline
  4 & 1 & 0 & 0.5 & 0.5 & R1=R1+\frac{R2}{2}\\
  2 & 0 & 1 & -0.5 & 0.5 & R2 = \frac{R2}{2}\\\hline
\end{array}
$$

The corresponding basic feasible solution is $x=\begin{pmatrix}4 & 2 & 0 & 0\end{pmatrix}$


At this point, all reduced costs are non-negative and the algorithm terminates. Our optimal basic feasible solution is $x=\begin{pmatrix}4 & 2 & 0 & 0\end{pmatrix}$.

\subsection{c}

\begin{figure}[h]
\includegraphics[width=0.5\textwidth]{4c}
\centering
\caption{The geometry of the minimization problem (red) and the path taken by the simplex algorithm (blue)}
\end{figure}

\end{document}